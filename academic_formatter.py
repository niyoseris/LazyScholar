#!/usr/bin/env python3
"""
Academic Formatter - A tool to format LazyScholar's final paper as a proper academic paper

This script:
1. Reads the final paper generated by LazyScholar
2. Reformats it as a proper academic paper with in-text citations
3. Formats the references section according to APA style
4. Creates a new version of the final paper with academic formatting
"""

import os
import re
import logging
import argparse
from pathlib import Path
import google.generativeai as genai
from dotenv import load_dotenv
import json
import PyPDF2
import requests
import time
from PIL import Image

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler("academic_formatter.log")
    ]
)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    logger.error("GOOGLE_API_KEY not found in environment variables. Please set it in .env file.")
    exit(1)

# Configure Google Generative AI
genai.configure(api_key=GOOGLE_API_KEY)

def initialize_model():
    """Initialize the Gemini model for text generation."""
    try:
        # Check for API key in environment variables
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            api_key = os.getenv("GEMINI_API_KEY")
            
        if not api_key:
            logger.error("No API key found. Please set GOOGLE_API_KEY or GEMINI_API_KEY environment variable.")
            return None
        
        # Configure the Gemini API
        genai.configure(api_key=api_key)
        
        # Initialize the model
        model = genai.GenerativeModel('gemini-2.0-flash-exp')
        
        # Test the model with a simple prompt
        test_prompt = "Respond with 'OK' if you can process this message."
        response = model.generate_content(test_prompt)
        
        if response and hasattr(response, 'text'):
            logger.info("Successfully initialized Gemini model")
            return model
        else:
            logger.error("Failed to get valid response from Gemini model")
            return None
    except Exception as e:
        logger.error(f"Error initializing Gemini model: {str(e)}")
        return None

def extract_metadata_from_pdf(pdf_path):
    """Extract metadata from a PDF file."""
    try:
        import PyPDF2
        import google.generativeai as genai
        from PIL import Image
        import os
        
        # First try to get metadata from PDF file properties
        metadata = {}
        
        with open(pdf_path, 'rb') as file:
            reader = PyPDF2.PdfReader(file)
            
            # Try to get info from PDF metadata
            if reader.metadata:
                if '/Title' in reader.metadata and reader.metadata['/Title']:
                    metadata['title'] = reader.metadata['/Title']
                if '/Author' in reader.metadata and reader.metadata['/Author']:
                    metadata['authors'] = reader.metadata['/Author']
                if '/CreationDate' in reader.metadata and reader.metadata['/CreationDate']:
                    date_str = reader.metadata['/CreationDate']
                    year_pattern = re.compile(r'(19|20)\d{2}')
                    year_match = year_pattern.search(date_str)
                    if year_match:
                        metadata['year'] = year_match.group(0)
            
            # Extract text from first page to try to get title and authors
            if len(reader.pages) > 0:
                first_page_text = reader.pages[0].extract_text()
                
                # If we don't have a title yet, try to extract it from the first page
                if 'title' not in metadata or not metadata['title']:
                    title_lines = first_page_text.split('\n')[:3]  # First 3 lines might contain the title
                    metadata['title'] = ' '.join(title_lines).strip()
                
                # If we don't have a year yet, try to find it in the first page
                if 'year' not in metadata or not metadata['year']:
                    year_pattern = re.compile(r'(19|20)\d{2}')  # Match years from 1900-2099
                    year_matches = year_pattern.findall(os.path.basename(pdf_path))
                    if year_matches:
                        metadata['year'] = year_matches[0]
                    else:
                        # Try to find year in first page text
                        year_matches = year_pattern.findall(first_page_text[:500])  # Check first 500 chars
                        if year_matches:
                            metadata['year'] = year_matches[0]
                        else:
                            metadata['year'] = "n.d."  # No date
                
                # If we don't have authors yet, try to extract them from the first page
                if 'authors' not in metadata or not metadata['authors']:
                    # Look for common patterns like "by" or "Author:" in first 500 chars
                    author_section = first_page_text[:500]
                    author_pattern = re.compile(r'(?:by|authors?:|written by)[:\s]+([^,\.;]+(?:,\s*[^,\.;]+){0,5})', re.IGNORECASE)
                    author_match = author_pattern.search(author_section)
                    if author_match:
                        metadata['authors'] = author_match.group(1).strip()
                    else:
                        # Just use the filename as a fallback
                        base_name = os.path.basename(pdf_path).replace('.pdf', '')
                        metadata['authors'] = base_name.split('_')[0] if '_' in base_name else base_name
        
        # If we still have missing or problematic metadata, use the LLM to extract it
        if not metadata.get('title') or not metadata.get('authors') or metadata.get('title') == "Microsoft Word" or "syllabus.doc" in metadata.get('title', ''):
            try:
                # Initialize the Gemini model for vision tasks
                api_key = os.environ.get("GEMINI_API_KEY")
                if not api_key:
                    api_key = os.environ.get("GOOGLE_API_KEY")
                    
                if api_key:
                    genai.configure(api_key=api_key)
                    model = genai.GenerativeModel('gemini-2.0-flash-exp')
                    
                    # Create a prompt for the model
                    prompt = """
                    You are an expert at extracting academic citation information from PDFs.
                    Please extract the following information from this PDF:
                    1. Title of the paper/document
                    2. Author(s)
                    3. Publication year
                    4. Journal or publisher (if available)
                    
                    Format your response as a JSON object with these fields:
                    {
                        "title": "The full title",
                        "authors": "Author names in format: Last, First M.",
                        "year": "YYYY",
                        "journal": "Journal name or publisher"
                    }
                    
                    If any information is not available, use "Unknown" for that field.
                    """
                    
                    # Send the PDF directly to the model
                    with open(pdf_path, 'rb') as f:
                        pdf_data = f.read()
                    
                    # Convert first page to image if possible
                    try:
                        import fitz  # PyMuPDF
                        doc = fitz.open(stream=pdf_data, filetype="pdf")
                        pix = doc[0].get_pixmap()
                        img_path = f"{pdf_path}_temp.png"
                        pix.save(img_path)
                        
                        # Send the image to the model with retry
                        img = Image.open(img_path)
                        response = api_call_with_retry(lambda: model.generate_content([prompt, img]))
                        
                        # Clean up temporary image
                        os.remove(img_path)
                        
                        # Parse the JSON response
                        import json
                        try:
                            # Extract JSON from the response
                            json_str = response.text
                            # Find JSON object in the response if it's not pure JSON
                            json_match = re.search(r'\{.*\}', json_str, re.DOTALL)
                            if json_match:
                                json_str = json_match.group(0)
                            
                            llm_metadata = json.loads(json_str)
                            
                            # Update metadata with LLM-extracted information
                            if llm_metadata.get('title') and llm_metadata['title'] != "Unknown":
                                metadata['title'] = llm_metadata['title']
                            if llm_metadata.get('authors') and llm_metadata['authors'] != "Unknown":
                                metadata['authors'] = llm_metadata['authors']
                            if llm_metadata.get('year') and llm_metadata['year'] != "Unknown":
                                metadata['year'] = llm_metadata['year']
                            if llm_metadata.get('journal') and llm_metadata['journal'] != "Unknown":
                                metadata['journal'] = llm_metadata['journal']
                        except Exception as e:
                            logger.warning(f"Error parsing LLM response: {str(e)}")
                    except Exception as e:
                        logger.warning(f"Error converting PDF to image: {str(e)}")
            except Exception as e:
                logger.warning(f"Error using LLM for metadata extraction: {str(e)}")
        
        # Clean up metadata
        if 'title' in metadata and metadata['title']:
            # Remove "Microsoft Word -" and similar prefixes
            metadata['title'] = re.sub(r'^Microsoft Word\s*-\s*', '', metadata['title'])
            # Remove file extensions
            metadata['title'] = re.sub(r'\.docx?$|\.pdf$', '', metadata['title'])
            # Clean up title
            metadata['title'] = re.sub(r'[_\-]', ' ', metadata['title']).strip()
        
        return metadata
    except Exception as e:
        logger.error(f"Error extracting metadata from PDF {pdf_path}: {str(e)}")
        # Return basic metadata based on filename
        base_name = os.path.basename(pdf_path).replace('.pdf', '')
        parts = base_name.split('_')
        return {
            'title': ' '.join(parts[1:]) if len(parts) > 1 else base_name,
            'authors': parts[0] if len(parts) > 1 else "Unknown",
            'year': "n.d."
        }

def extract_references_from_final_paper(final_paper_path):
    """Extract the current references from the final paper and find corresponding PDFs."""
    try:
        with open(final_paper_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Get the PDF directory - check multiple possible locations
        possible_pdf_dirs = [
            os.path.join(os.path.dirname(os.path.dirname(final_paper_path)), "pdfs"),
            os.path.join(os.path.dirname(final_paper_path), "pdfs"),
            os.path.join(os.path.dirname(final_paper_path), "..", "pdfs"),
            os.path.join(os.path.dirname(final_paper_path), "research_output", "pdfs"),
            os.path.join(os.path.dirname(os.path.dirname(final_paper_path)), "research_output", "pdfs")
        ]
        
        pdf_files = []
        for pdf_dir in possible_pdf_dirs:
            if os.path.exists(pdf_dir):
                pdf_files.extend([os.path.join(pdf_dir, f) for f in os.listdir(pdf_dir) if f.endswith('.pdf')])
                logger.info(f"Found {len(pdf_files)} PDF files in {pdf_dir}")
                break
        
        # If no PDFs found in standard directories, search for PDF mentions in the content
        if not pdf_files:
            # Look for PDF mentions in the content
            pdf_pattern = re.compile(r'([^\/\s]+\.pdf)')
            pdf_mentions = set()
            for match in pdf_pattern.finditer(content):
                pdf_mentions.add(match.group(1))
            
            if pdf_mentions:
                logger.info(f"Found {len(pdf_mentions)} PDF mentions in the paper")
                # Try to locate these PDFs
                for pdf_dir in possible_pdf_dirs:
                    if os.path.exists(pdf_dir):
                        for pdf_file in pdf_mentions:
                            pdf_path = os.path.join(pdf_dir, pdf_file)
                            if os.path.exists(pdf_path) and pdf_path not in pdf_files:
                                pdf_files.append(pdf_path)
            
            # If still no PDFs found, search in the entire project directory
            if not pdf_files:
                logger.info("Searching for PDFs in the entire project directory...")
                project_dir = os.path.dirname(os.path.dirname(final_paper_path))
                for root, _, files in os.walk(project_dir):
                    for file in files:
                        if file.endswith('.pdf'):
                            pdf_path = os.path.join(root, file)
                            pdf_files.append(pdf_path)
                            logger.info(f"Found PDF: {pdf_path}")
                
                logger.info(f"Found {len(pdf_files)} PDF files in the project directory")
        
        # Extract references section
        references = []
        references_match = re.search(r'## References\s*\n(.*?)(?:\n#|\Z)', content, re.DOTALL)
        if references_match:
            references_section = references_match.group(1).strip()
            
            # Extract individual references with various patterns
            ref_patterns = [
                # Numbered references
                re.compile(r'(?:^|\n)(?:\d+\.\s+)?(.*?)(?=\n\d+\.|$)', re.DOTALL),
                # Topic-subtopic references
                re.compile(r'\*\*.*?\*\*:\s*(.*?)(?=\n\*\*|\Z)', re.DOTALL)
            ]
            
            for pattern in ref_patterns:
                for match in pattern.finditer(references_section):
                    ref_text = match.group(1).strip()
                    if ref_text and not ref_text.startswith("No references"):
                        # Split multi-line references
                        for ref in ref_text.split('\n'):
                            ref = ref.strip()
                            if ref:
                                references.append(ref)
            
            logger.info(f"Extracted {len(references)} references from the paper")
        
        # Extract in-text citations
        citation_patterns = [
            re.compile(r'\(([^)]+?, \d{4}[a-z]?)\)'),  # APA style (Author, Year)
            re.compile(r'([A-Z][a-z]+ et al\., \d{4})'),  # Author et al., Year
        ]
        
        citations = set()
        for pattern in citation_patterns:
            for match in pattern.finditer(content):
                citation = match.group(1).strip()
                citations.add(citation)
        
        logger.info(f"Found {len(citations)} in-text citations in the paper")
        
        # If we have references but no PDFs, try to find PDFs based on reference text
        if references and not pdf_files:
            logger.info("Trying to find PDFs based on reference text...")
            for ref in references:
                # Extract potential filenames from references
                words = re.findall(r'\b\w+\b', ref.lower())
                for pdf_dir in possible_pdf_dirs:
                    if os.path.exists(pdf_dir):
                        for pdf_file in os.listdir(pdf_dir):
                            if pdf_file.endswith('.pdf'):
                                # Check if key words from reference appear in filename
                                pdf_lower = pdf_file.lower()
                                if any(word in pdf_lower for word in words if len(word) > 3):
                                    pdf_path = os.path.join(pdf_dir, pdf_file)
                                    if pdf_path not in pdf_files:
                                        pdf_files.append(pdf_path)
                                        logger.info(f"Found matching PDF: {pdf_file} for reference: {ref[:50]}...")
        
        return pdf_files, content
    except Exception as e:
        logger.error(f"Error extracting references: {str(e)}")
        return [], ""

def generate_academic_citations(pdf_paths):
    """Generate academic citations in APA format based on PDF metadata."""
    citations = []
    
    for pdf_path in pdf_paths:
        try:
            metadata = extract_metadata_from_pdf(pdf_path)
            
            # Format authors
            authors = metadata.get('authors', '')
            if not authors or authors == "Unknown":
                # Try to extract author from filename
                base_name = os.path.basename(pdf_path).replace('.pdf', '')
                parts = base_name.split('_')
                if len(parts) > 1:
                    authors = parts[0].replace('-', ' ').title()
                else:
                    authors = "Unknown Author"
            
            # Clean up authors
            authors = re.sub(r'[_\-]', ' ', authors)
            
            # Format title
            title = metadata.get('title', '')
            if not title or len(title) < 5:
                # Use filename as title
                base_name = os.path.basename(pdf_path).replace('.pdf', '')
                parts = base_name.split('_')
                if len(parts) > 1:
                    title = ' '.join(parts[1:]).replace('-', ' ').title()
                else:
                    title = base_name.replace('-', ' ').title()
            
            # Clean up title
            title = re.sub(r'[_\-]', ' ', title)
            
            # Format year
            year = metadata.get('year', '')
            if not year or year == "n.d.":
                # Try to extract year from filename or title
                year_pattern = re.compile(r'(19|20)\d{2}')
                year_match = year_pattern.search(os.path.basename(pdf_path))
                if year_match:
                    year = year_match.group(0)
                elif year_pattern.search(title):
                    year = year_pattern.search(title).group(0)
                else:
                    year = "n.d."
            
            # Create citation in APA format
            if ',' in authors:
                # Multiple authors
                citation = f"{authors} ({year}). {title}."
            else:
                # Single author
                citation = f"{authors} ({year}). {title}."
            
            citations.append(citation)
        except Exception as e:
            logger.error(f"Error generating citation for {pdf_path}: {str(e)}")
            # Create a basic citation from the filename
            base_name = os.path.basename(pdf_path).replace('.pdf', '')
            parts = base_name.split('_')
            if len(parts) > 1:
                author = parts[0].replace('-', ' ').title()
                title = ' '.join(parts[1:]).replace('-', ' ').title()
                citations.append(f"{author} (n.d.). {title}.")
            else:
                citations.append(f"{base_name.replace('-', ' ').title()} (n.d.).")
    
    return citations

def api_call_with_retry(func, max_retries=5, initial_delay=2):
    """Execute an API call with retry logic and exponential backoff for rate limiting."""
    retry_count = 0
    delay = initial_delay
    
    while retry_count < max_retries:
        try:
            return func()
        except Exception as e:
            error_str = str(e)
            if "429" in error_str or "quota" in error_str.lower() or "exhausted" in error_str.lower():
                retry_count += 1
                if retry_count >= max_retries:
                    logger.error(f"Maximum retries reached. Last error: {error_str}")
                    raise
                
                wait_time = delay * (2 ** (retry_count - 1))  # Exponential backoff
                logger.warning(f"API quota exhausted. Waiting {wait_time} seconds before retry {retry_count}/{max_retries}...")
                time.sleep(wait_time)
            else:
                # If it's not a quota error, re-raise immediately
                logger.error(f"API error (not quota related): {error_str}")
                raise
    
    # This should not be reached due to the raise in the loop
    raise Exception("Maximum retries exceeded")

def detect_language(model, text, default_language="en"):
    """Detect the language of a text with retry mechanism."""
    if not text or len(text.strip()) < 20:
        return default_language
        
    language_prompt = f"""
    Detect the language of the following text. Return only the language code (e.g., 'en' for English, 'tr' for Turkish, etc.):
    
    {text[:1000]}
    """
    
    try:
        language_response = api_call_with_retry(lambda: model.generate_content(language_prompt))
        detected_language = language_response.text.strip().lower()
        
        # Normalize language code
        if detected_language in ['english', 'en', 'en-us', 'en-gb']:
            return 'en'
        elif detected_language in ['turkish', 'tr', 'türkçe', 'turkce']:
            return 'tr'
        else:
            return default_language
    except Exception as e:
        logger.warning(f"Error detecting language: {str(e)}")
        return default_language

def translate_text(model, text, source_language, target_language):
    """Translate text from source language to target language with retry mechanism."""
    if source_language == target_language:
        return text
        
    translation_prompt = f"""
    Translate the following text from {source_language} to {'English' if target_language == 'en' else 'Turkish'}.
    Maintain the academic style and terminology. Keep any citations in their original format.
    
    {text}
    """
    
    try:
        translation_response = api_call_with_retry(lambda: model.generate_content(translation_prompt))
        return translation_response.text.strip()
    except Exception as e:
        logger.warning(f"Error translating text: {str(e)}")
        return text  # Return original text if translation fails

def format_as_academic_paper(model, content, pdf_paths, preferred_language="auto"):
    """Format the content as an academic paper with in-text citations."""
    try:
        # Step 1: Parse the original paper structure
        sections = {}
        current_section = None
        section_content = []
        title = None
        
        # Extract title and sections
        for line in content.split('\n'):
            if line.startswith('# '):
                title = line[2:].strip()
            elif line.startswith('## '):
                # Save previous section if any
                if current_section:
                    sections[current_section] = section_content
                
                # Start new section
                current_section = line[3:].strip()
                section_content = []
            elif current_section:
                section_content.append(line)
        
        # Save the last section
        if current_section and section_content:
            sections[current_section] = section_content
        
        # Step 2: Extract existing references
        references = []
        if "References" in sections:
            ref_content = '\n'.join(sections["References"])
            # Extract references with various patterns
            ref_patterns = [
                # Numbered references
                re.compile(r'(?:^|\n)(?:\d+\.\s+)?(.*?)(?=\n\d+\.|$)', re.DOTALL),
                # Topic-subtopic references
                re.compile(r'\*\*.*?\*\*:\s*(.*?)(?=\n\*\*|\Z)', re.DOTALL)
            ]
            
            for pattern in ref_patterns:
                for match in pattern.finditer(ref_content):
                    ref_text = match.group(1).strip()
                    if ref_text and not ref_text.startswith("No references"):
                        # Split multi-line references
                        for ref in ref_text.split('\n'):
                            ref = ref.strip()
                            if ref and len(ref) > 5:  # Minimal length check
                                references.append(ref)
        
        # Step 3: Extract citations from PDF metadata
        pdf_citations = []
        for pdf_path in pdf_paths:
            try:
                metadata = extract_metadata_from_pdf(pdf_path)
                
                # Format authors
                authors = metadata.get('authors', 'Unknown')
                
                # Format title
                title_text = metadata.get('title', os.path.basename(pdf_path).replace('.pdf', ''))
                
                # Format year
                year = metadata.get('year', 'n.d.')
                
                # Format journal/publisher if available
                journal = metadata.get('journal', '')
                
                # Create citation in APA format
                if journal:
                    citation = f"{authors} ({year}). {title_text}. {journal}."
                else:
                    citation = f"{authors} ({year}). {title_text}."
                pdf_citations.append(citation)
            except Exception as e:
                logger.warning(f"Error creating citation for {pdf_path}: {str(e)}")
        
        # Step 4: Combine all references, removing duplicates
        all_references = []
        seen_refs = set()
        
        # Process existing references first
        for ref in references:
            # Clean up reference
            ref = re.sub(r'^SOURCE \d+:\s*', '', ref)  # Remove SOURCE prefix
            ref = re.sub(r'^\d+\.\s+', '', ref)  # Remove numbering
            
            # Skip if empty or too short
            if not ref or len(ref) < 5:
                continue
                
            # Check if it's a filename
            if ref.lower().endswith('.pdf'):
                # Try to find a better citation for this PDF
                found_better = False
                for pdf_citation in pdf_citations:
                    if ref.lower() in pdf_citation.lower():
                        if pdf_citation not in seen_refs:
                            seen_refs.add(pdf_citation)
                            all_references.append(pdf_citation)
                            found_better = True
                            break
                
                # If no better citation found, use as is
                if not found_better and ref not in seen_refs:
                    seen_refs.add(ref)
                    all_references.append(ref)
            else:
                # Use the reference as is if not already included
                if ref not in seen_refs:
                    seen_refs.add(ref)
                    all_references.append(ref)
        
        # Add remaining PDF citations
        for citation in pdf_citations:
            if citation not in seen_refs:
                seen_refs.add(citation)
                all_references.append(citation)
        
        # Step 5: Determine the target language
        if preferred_language == "auto":
            # Create a sample text from the paper content for language detection
            sample_text = title + "\n"
            for section_name, section_lines in sections.items():
                if section_name != "References" and len(section_lines) > 0:
                    sample_text += "\n".join(section_lines[:min(10, len(section_lines))])
                    break
            
            main_language = detect_language(model, sample_text, default_language="en")
            logger.info(f"Auto-detected main language: {main_language}")
        else:
            main_language = preferred_language
            logger.info(f"Using user-specified language: {main_language}")
        
        # Step 6: Format the paper with consistent language and in-text citations
        formatted_sections = {}
        
        # Process each section
        total_sections = len(sections) - (1 if "References" in sections else 0)
        processed_sections = 0
        
        for section_name, section_lines in sections.items():
            if section_name == "References":
                continue  # Skip references section, we'll create a new one
            
            processed_sections += 1
            print(f"Processing section {processed_sections}/{total_sections}: {section_name}")
            
            section_text = "\n".join(section_lines)
            
            # Check if this section needs language correction
            if len(section_text) > 50:  # Only check substantial sections
                section_language = detect_language(model, section_text[:500], default_language=main_language)
                
                # If section language doesn't match main language, translate it
                if section_language != main_language:
                    logger.info(f"Translating section '{section_name}' from {section_language} to {main_language}")
                    print(f"  - Translating from {section_language} to {main_language}...")
                    section_text = translate_text(model, section_text, section_language, main_language)
            
            # Format in-text citations
            print(f"  - Formatting citations...")
            citation_prompt = f"""
            Format the following academic text with proper in-text citations. Use the APA style for in-text citations.
            The text already contains some citations, but they may not be in the correct format.
            DO NOT add any new information or change the meaning of the text.
            DO NOT add any citations that are not already present in the text.
            
            Here are the available references:
            {chr(10).join([f"- {ref}" for ref in all_references[:20]])}
            
            Text to format:
            {section_text}
            """
            
            try:
                citation_response = api_call_with_retry(lambda: model.generate_content(citation_prompt))
                formatted_text = citation_response.text.strip()
                formatted_sections[section_name] = formatted_text.split('\n')
            except Exception as e:
                logger.warning(f"Error formatting citations in section {section_name}: {str(e)}")
                formatted_sections[section_name] = section_lines
        
        # Step 7: Assemble the formatted paper
        formatted_paper = f"```markdown\n# {title}\n\n"
        
        # Add each formatted section
        for section_name, section_lines in formatted_sections.items():
            formatted_paper += f"## {section_name}\n\n"
            formatted_paper += "\n".join(section_lines) + "\n\n"
        
        # Add references section
        formatted_paper += "## References\n\n"
        for i, ref in enumerate(all_references):
            formatted_paper += f"{i+1}. {ref}\n\n"
        
        formatted_paper += "```"
        
        return formatted_paper
    except Exception as e:
        logger.error(f"Error formatting academic paper: {str(e)}")
        return None

def save_formatted_paper(final_paper_path, formatted_paper):
    """Save the formatted paper to a new file."""
    try:
        # Create the output path
        output_path = final_paper_path.replace(".md", "_academic_format.md")
        
        # Write the formatted paper
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(formatted_paper)
        
        logger.info(f"Saved formatted academic paper to {output_path}")
        return output_path
    except Exception as e:
        logger.error(f"Error saving formatted paper: {str(e)}")
        return None

def parse_arguments():
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(description="Format LazyScholar's final paper as an academic paper")
    parser.add_argument(
        "--input",
        default="research_output/final_paper.md",
        help="Path to the input final paper (default: research_output/final_paper.md)"
    )
    parser.add_argument(
        "--preserve-structure",
        action="store_true",
        default=True,
        help="Preserve the original paper structure (default: True)"
    )
    parser.add_argument(
        "--language",
        choices=["auto", "en", "tr"],
        default="auto",
        help="Preferred language for the paper (auto, en, tr) (default: auto)"
    )
    return parser.parse_args()

def main():
    """Main function to format the final paper as an academic paper."""
    logger.info("Starting academic paper formatting process...")
    
    # Parse arguments
    args = parse_arguments()
    
    # Check for required dependencies
    try:
        import PyPDF2
    except ImportError:
        logger.warning("PyPDF2 not installed. Installing...")
        try:
            import subprocess
            subprocess.check_call(["pip", "install", "PyPDF2"])
            logger.info("PyPDF2 installed successfully")
        except Exception as e:
            logger.error(f"Failed to install PyPDF2: {str(e)}")
            return
    
    try:
        import fitz  # PyMuPDF
    except ImportError:
        logger.warning("PyMuPDF not installed. Installing...")
        try:
            import subprocess
            subprocess.check_call(["pip", "install", "PyMuPDF"])
            logger.info("PyMuPDF installed successfully")
        except Exception as e:
            logger.error(f"Failed to install PyMuPDF: {str(e)}")
            logger.warning("Continuing without PyMuPDF - some PDF processing features may be limited")
    
    # Initialize model
    print("Initializing AI model...")
    model = initialize_model()
    if not model:
        logger.error("Failed to initialize model. Exiting.")
        return
    
    # Check if input file exists
    final_paper_path = args.input
    if not os.path.exists(final_paper_path):
        logger.error(f"Final paper not found at {final_paper_path}")
        return
    
    try:
        # Extract references and content
        print("Extracting references and content from paper...")
        logger.info(f"Extracting references from {final_paper_path}")
        pdf_paths, content = extract_references_from_final_paper(final_paper_path)
        
        if not content:
            logger.error("Failed to read content from the paper")
            return
            
        print(f"Found {len(pdf_paths)} PDF files for citation generation")
        logger.info(f"Found {len(pdf_paths)} PDF files for citation generation")
        
        # Format as academic paper
        print("\nFormatting paper as academic document...")
        print("This process may take some time as we ensure all sections are in the preferred language.")
        print("The system will automatically handle any API quota limitations by waiting when necessary.\n")
        
        logger.info("Formatting paper as academic document...")
        formatted_paper = format_as_academic_paper(model, content, pdf_paths, args.language)
        
        # Validate the formatted paper
        if not formatted_paper or len(formatted_paper) < 100:
            logger.error("Formatting failed - output is too short or empty")
            return
            
        # Save formatted paper
        print("Saving formatted paper...")
        output_path = save_formatted_paper(final_paper_path, formatted_paper)
        logger.info(f"Formatted paper saved to {output_path}")
        
        print(f"\n✅ Academic paper formatting complete!")
        print(f"Output file: {output_path}")
        print("\nAll sections have been processed and translated to the preferred language.")
        print("Citations have been properly formatted according to academic standards.")
        
    except KeyboardInterrupt:
        print("\n\nProcess interrupted by user. Exiting...")
        logger.warning("Process interrupted by user")
    except Exception as e:
        logger.error(f"Error in main process: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        print(f"\n❌ Error: {str(e)}")
        print("Please check the academic_formatter.log file for details.")

if __name__ == "__main__":
    main() 